{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62df3ae9",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from dsc.notebook import embed_website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771c804",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "- In this chapter we discuss how to setup your Python project after you have created a Git repo and a virtual environment\n",
    "- We talk about how you can rapidly develop prototypes and conduct analyses in Jupyter notebooks and when you should modularize your code into modules or a package.\n",
    "- In particular, we will use [PyScaffold](https://github.com/pyscaffold) in combination with the [datascience template](https://github.com/drivendata/cookiecutter-data-science/) of [Cookiecutter](https://www.cookiecutter.io/) so that\n",
    "    - Obtain a sound folder structure for your project so that you know where to put\n",
    "        - Data\n",
    "        - Notebooks\n",
    "        - Modules\n",
    "        - Reports\n",
    "        - ...  \n",
    "    - You can easily pip-install your project package in editable mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bbe95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07e794",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Jupyter notebooks are heavily used in the data science community (industry, science, kaggle)\n",
    "- Notebooks are wonderful for prototyping, exploration, analyses (including visualizations) and sharing results.\n",
    "    - Combing markdown with source code of many programming languages\n",
    "    - Seperating of code blocks into cells\n",
    "    - Plotting\n",
    "- There are even companies that \n",
    "    - Use Jupyter notebooks in production systems, e.g., [Netflix](https://netflixtechblog.com/notebook-innovation-591ee3221233)\n",
    "    - Provide [platforms](https://www.databricks.com/solutions/data-science) that productionize notebooks \n",
    "<!-- (but if you don't need Spark, Databricks might be too expensive)-->\n",
    "- However, the use of Jupyter notebooks for code that is actually deployed and runs in production is rather the exception.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41767a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "And there are good reasons for that!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c3ffb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"./figures/all_code_in_notebook_meme.png\" alt=\"Notebook meme\" width=1000/>\n",
    "<div/>\n",
    "<div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133db5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The (in)famous talk [\"I don't like notebooks\"](https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI/) given by Joel Grus at JupyterCon 2018 highlights possible drawbacks of Jupyter notebooks for coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1a1bed8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# embed_website(\"https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI/\")  # activating this might lag the presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562cf818",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In the talk the following **drawbacks of Jupyter notebooks** are mentioned:\n",
    "    1. **Reproducibility and hidden states** are a concern (slides 23, 24, 31, 42, 73-74)\n",
    "        - Re-running or running cells in different order give you much flexibility for exploring\n",
    "        - But it can be difficult to reproduce or understand results\n",
    "    1. Inspiring bad coding habits and **discouraging good coding habits** (slides 45-59, 76-90)\n",
    "        - No functions, abstractions or OOP, no writing of modules/packages\n",
    "        - Mixing \"library\" and \"excecution\" code\n",
    "        - Code is often not DRY and resuable\n",
    "        - No testing\n",
    "        - No type annotations\n",
    "    1. **Powerful features of IDEs are missing** (slides 60-70, this can be somewhat addressed in the meantime by opening a notebook directly in VSCode or PyCharm)\n",
    "        - Autosuggestion\n",
    "        - Automatic highlighting of possible errors by linters\n",
    "        - Code formatting using, e.g., black\n",
    "        - Type annotation checkers\n",
    "<!-- - The author also mentions in his notes that the Jupyter ecosystem consists of tools to work around people's bad habits so they don't have to fix them -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d67239a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Drawbacks not mentioned in the talk:\n",
    "    - **Code versioning is difficult** (in the meantime, this can be addressed with Jupytext)\n",
    "    - **Collaboration is difficult** (everybody working on the same notebook? merge conflicts?)\n",
    "- See also [here](https://www.reddit.com/r/datascience/comments/nf47se/does_netflix_use_jupyter_notebooks_in_production/) and [here](https://www.youtube.com/watch?v=9Q6sLbz37gk)\n",
    "for further discussions about using notebooks in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e1396",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Jupyter notebooks and its extensions are tools. \n",
    "    - Many **projects try to extend Jupyter notebooks and make them ready for collaboration and production** (or e.g., writing books with them).\n",
    "    - Like any tool you can use a notebook for a purpose it was not designed for: [\"If Your Only Tool Is a Hammer Then Every Problem Looks Like a Nail\"](https://en.wikipedia.org/wiki/Law_of_the_instrument).\n",
    "- Much \"data science\" education appears to be limited to showing beginners how to use notebooks but does not develop their programming skills or teach best practices.\n",
    "- Instead of extending and productionizing notebooks **I think it makes more sense to empower data scientists to build production-ready code the way it is typically done in other areas**\n",
    "- Especially if you project becomes more mature or complex it is beneficial to move away from notebooks and modularize your\n",
    "  code and factor it into a package/module\n",
    "- When the time comes, you'll be much closer to production-grade code and can rather ensure scalability, maintainability and resiliency that long-lived production code needs to support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57024401",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using PyScaffold for setting up your Python project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6db66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is PyScaffold?\n",
    "From the [website](https://pyscaffold.org/en/stable/):\n",
    "\n",
    "- PyScaffold is a **project generator** for bootstrapping high-quality Python packages, ready to be shared on PyPI and installable via pip. \n",
    "- PyScaffold incentives its users to use the **best tools and practices** available in the Python ecosystem.\n",
    "\n",
    "    - A generated project will contain **sane default configurations** for \n",
    "        - Setuptools (the de facto standard for building Python packages)\n",
    "        - Sphinx (the one & only Python documentation tool)\n",
    "        - Pytest and tox (most commonly used Python testing framework & task runner)\n",
    "    -  PyScaffold can also bring pre-commit into the mix to run a set of prolific linters and automatic formatters in each commit in order to adhere to common coding standards like pep8 and black."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f63ce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\"Using PyScaffold is like having a Python Packaging Guru, who has spent a lot of time researching how to create the best project setups, as a friend that is helping you with your project.\" &#128515;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e16cfc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Moreover, there is a [PyScaffold extension tailored for Data Science projects](https://github.com/pyscaffold/pyscaffoldext-dsproject) \t&#128522;\n",
    "- This extension creates a folder structure that is inspired by [cookiecutter-data-science](https://github.com/drivendata/cookiecutter-data-science). In contrast to cookiecutter-data-science alone it\n",
    "    1. Advocates a proper Python package structure that can be shipped and distributed.\n",
    "    2. Uses a conda environment instead of something virtualenv-based and is thus more suitable for data science projects.\n",
    "    3. More default configurations for Sphinx, pytest, pre-commit, etc. to foster clean coding and best practice.\n",
    "\n",
    "<!-- Cookiecutter is a tool that allows the definition of templates \n",
    "for a broad range of software projects. On the other hand, PyScaffold focus is on developing distributable Python packages (exclusively) in a simple way\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262bc55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In this course, we will only use a subset of the features that the standard PyScaffold (DataScience) provides:\n",
    "    - A sound folder structure\n",
    "    - Using it to easily install the project package in editable mode\n",
    "    - Settinp up documentation for a package \n",
    "    - Setting up pre-commit hooks (will be discussed when we talk about collaboration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e50d7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing PyScaffold and creating a project with PyScaffold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d17826",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Cd into a location that is not a git repo (e.g., \"../dsc_2022\").\n",
    "- Run ```conda create -n pyscaffold_test -c conda-forge pyscaffoldext-dsproject```\n",
    "- Activate the pyscaffold_test environment\n",
    "- Run ```putup --dsproject pyscaffold_test``` to create a directory called pyscaffold_test which is set up by PyScaffold\n",
    "- Note that PyScaffold automatically turns pyscaffold_test into a git repo (please rename the initial branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb061ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The resulting folder structure should look like this\n",
    "\n",
    "```\n",
    "├── AUTHORS.md              <- List of developers and maintainers.\n",
    "├── CHANGELOG.md            <- Changelog to keep track of new features and fixes.\n",
    "├── CONTRIBUTING.md         <- Guidelines for contributing to this project.\n",
    "├── Dockerfile              <- Build a docker container with `docker build .`.\n",
    "├── LICENSE.txt             <- License as chosen on the command-line.\n",
    "├── README.md               <- The top-level README for developers.\n",
    "├── configs                 <- Directory for configurations of model & application.\n",
    "├── data\n",
    "│   ├── external            <- Data from third party sources.\n",
    "│   ├── interim             <- Intermediate data that has been transformed.\n",
    "│   ├── processed           <- The final, canonical data sets for modeling.\n",
    "│   └── raw                 <- The original, immutable data dump.\n",
    "├── docs                    <- Directory for Sphinx documentation in rst or md.\n",
    "├── environment.yml         <- The conda environment file for reproducibility.\n",
    "├── models                  <- Trained and serialized models, model predictions,\n",
    "│                              or model summaries.\n",
    "├── notebooks               <- Jupyter notebooks. Naming convention is a number (for\n",
    "│                              ordering), the creator's initials and a description,\n",
    "│                              e.g. `1.0-fw-initial-data-exploration`.\n",
    "├── pyproject.toml          <- Build configuration. Don't change! Use `pip install -e .`\n",
    "│                              to install for development or to build `tox -e build`.\n",
    "├── references              <- Data dictionaries, manuals, and all other materials.\n",
    "├── reports                 <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "│   └── figures             <- Generated plots and figures for reports.\n",
    "├── scripts                 <- Analysis and production scripts which import the\n",
    "│                              actual PYTHON_PKG, e.g. train_model.\n",
    "├── setup.cfg               <- Declarative configuration of your project.\n",
    "├── setup.py                <- [DEPRECATED] Use `python setup.py develop` to install for\n",
    "│                              development or `python setup.py bdist_wheel` to build.\n",
    "├── src\n",
    "│   └── PYTHON_PKG          <- Actual Python package where the main functionality goes.\n",
    "├── tests                   <- Unit tests which can be run with `pytest`.\n",
    "├── .coveragerc             <- Configuration for coverage reports of unit tests.\n",
    "├── .isort.cfg              <- Configuration for git hook that sorts imports.\n",
    "└── .pre-commit-config.yaml <- Configuration of pre-commit git hooks.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "comment_magics": false
  },
  "kernelspec": {
   "display_name": "Python [conda env:dsc]",
   "language": "python",
   "name": "conda-env-dsc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "rise": {
   "footer": "<h3>Dr. Fabian Spanhel</h3>",
   "header": "<h3>DSC: 2.2 PYTHON PROJECT</h3>"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
